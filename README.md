# saurav.github.io

###SUMMARY
Highly skilled data engineer with two-plus years of experience designing, building, and managing data pipelines. Proficient in PySpark, Hadoop,
Spark Streaming, Apache NiFi, and SQL, with experience in agile environments and cloud platforms. Proven ability to work collaboratively with
cross-functional teams to deliver timely and accurate data solutions. I am seeking a challenging role to leverage my technical skills and
problem-solving abilities to enhance data processing and analysis.
###EDUCATION
UNIVERSITY OF MASSACHUSETTS BOSTON Boston, MA
Masters in business Analytics Expected Sep 2023
Major in Big Data.
Cumulative GPA: 3.8/4.0.
Relevant Coursework: Business Intelligence, Data Mining, Project Mgt, Multivariate and Statistical analysis
VELLORE INSTITUTE OF TECHNOLOGY Vellore, IN
Bachelor of Engineering April 2015 – October 2019
Major in Computer Science; Minors in Economics
Cumulative GPA: 3.13/4.0.
Relevant Coursework: Data Analysis, Software Engineering, Operating Systems, Algorithms, Artificial Intelligence
###TECHNICAL SKILLS
Languages: Python, SQL, C, C++
Interests: Data Warehousing (Data Pipeline), Data Analysis, Data Modeling, ETL development
BI DS & ML: Pandas, NumPy, PySpark, Keras, TensorFlow, Matplotlib, PyTorch
Other Technologies: Apache Nifi, Kafka, Tableau, SSRS, PowerBI, Hadoop, Rapid Miner, PowerPivot, Snowpark, Streamlit
Cloud Technologies: AWS – S3, Snowflake, Azure
Data Reporting Tools: Sigma, Crystal
Data Cataloguing: Collibra ( using MetaCLI & Edge)
Databases: MySQL, Oracle, Db2, NoSQL, MongoDB, PostgreSQL
Agile Tools: Scrum, Kanban board, Jira, Agile Central
Soft Skills: Time management, Problem-Solving, Technical documentation, Troubleshooting, R&D
###WORK EXPERIENCE
DTCC Tampa,FL
IT Intern Jun 2023 – Aug 2023
● Deployed end-to-end data architecture solutions to the data enterprise teams.
● Created Reports using Crystal and Sigma reporting tools so as to gain any insights out of the raw data.
● Worked with the data cataloguing software called Collibra to better understand and manage the datasets.
● Implemented a data testing and validation framework in Snowflake using Snowpark.
Innovit USA Langhorne, PA
Data Engineering Intern Jan 2023 – May 2023
● Deployed 50+ automated processes & real-time data pipelines via Airflow, allowing 95% of customer analytics to be completed.
● Designed, built, and deployed data pipelines using PySpark, Hadoop, and Apache NiFi, increasing data processing speed by 30%.
● Optimized data pipelines using Spark Streaming and Apache Kafka, reducing processing time by 20%.
● Managed large datasets using SQL and NoSQL databases, ensuring data integrity and security.
Comviva (Yabx: Fintech startup) New Delhi, IN
Data Engineer (working for Bharti Airtel users as the client) Feb 2020 – Nov 2021
● Built and managed ETL pipelines using Python and Apache NiFi, increasing data processing efficiency by 25%.
● Worked with Amazon Web Services (AWS)cloud infrastructure services and was involved in ETL, Data Integration and Migration.
● Optimised data lake structure to facilitate proper storage & fast retrieval, resulting in a 15% boost to query performance.
● Participated in agile development processes using JIRA, ensuring timely and accurate delivery of data solutions.
● Configured Hadoop clusters and implemented optimized data ingestion pipelines, decreasing processing time by 30%.
###UNIVERSITY PROJECTS
DATA MINING AND BUSINESS INTELLIGENCE Oct 2022
● Credit Risk Management using the SVM model.
- This Project aims to analyze credit risk using machine learning.
- Used a classification data mining approach in this project.
● T20 Cricket World Cup Analysis using Tableau.
- Compare the performance of batters and bowlers by visualizing their stats in the form of bar graphs and box plots.
ANALYTICS AND SOFTWARE DEVELOPMENT Jan 2023
● Analysis of Play Store apps using R.
- To find out what factors contribute most to APP success in Google Play Store.
- Developed a roadmap for app developers to improve certain aspects of their products
● Consumer Behavior Analysis using Web Usage Mining.
- Developed a powerful tool that can help businesses gain valuable insights into consumer behaviour, preferences, and trends.
- By leveraging the data generated by web sources, businesses can make informed decisions and improve their competitiveness.
● Developing a Web Scraping tool to analyze 600M+ content pieces to analyze the progress made by other mental health organizations and
then running specific terms through the topic modeller designed by us using LDA. (ongoing)
RESEARCH PROJECT - AUTOMATED WEB-SCRAPING MODEL & TOPIC MODELER May 2023
● Gathered data from different mental health websites that focus on measurement-based care through web scraping.
● Applied topic modelling algorithms, such as Latent Dirichlet Allocation (LDA), to the saved CSV file and identify prevalent themes or
subjects within the mental health website data. (Using Gensim model)
